{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z6UHmLYVhWAN"
   },
   "source": [
    "# Project 1: Digit Classification with KNN and Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "03M_JSg3hWAO"
   },
   "source": [
    "In this project, you'll implement your own image recognition system for classifying digits. Read through the code and the instructions carefully and add your own code where indicated. Each problem can be addressed succinctly with the included packages -- please don't add any more. Grading will be based on writing clean, commented code, along with a few short answers.\n",
    "\n",
    "As always, you're welcome to work on the project in groups and discuss ideas on the course wall, but <b> please prepare your own write-up (with your own code). </b>\n",
    "\n",
    "If you're interested, check out these links related to digit recognition:\n",
    "\n",
    "* Yann Lecun's MNIST benchmarks: http://yann.lecun.com/exdb/mnist/\n",
    "* Stanford Streetview research and data: http://ufldl.stanford.edu/housenumbers/\n",
    "\n",
    "Finally, if you'd like to get started with Tensorflow, you can read through this tutorial: https://www.tensorflow.org/tutorials/keras/basic_classification. It uses a dataset called \"fashion_mnist\", which is identical in structure to the original digit mnist, but uses images of clothing rather than images of digits. The number of training examples and number of labels is the same. In fact, you can simply replace the code that loads \"fashion_mnist\" with \"mnist\" and everything should work fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iJ9ayCvyhWAP"
   },
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# Import a bunch of libraries.\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Set the randomizer seed so results are the same each time.\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sO1t0ypThWAR"
   },
   "source": [
    "Load the data. Notice that the data gets partitioned into training, development, and test sets. Also, a small subset of the training data called mini_train_data and mini_train_labels gets defined, which you should use in all the experiments below, unless otherwise noted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3yK9DacchWAS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (70000, 784)\n",
      "label shape: (70000,)\n"
     ]
    }
   ],
   "source": [
    "# Load the digit data from https://www.openml.org/d/554 or from default local location '~/scikit_learn_data/...'\n",
    "X, Y = fetch_openml(name='mnist_784', return_X_y=True, cache=False)\n",
    "\n",
    "\n",
    "# Rescale grayscale values to [0,1].\n",
    "X = X / 255.0\n",
    "\n",
    "# Shuffle the input: create a random permutation of the integers between 0 and the number of data points and apply this\n",
    "# permutation to X and Y.\n",
    "# NOTE: Each time you run this cell, you'll re-shuffle the data, resulting in a different ordering.\n",
    "shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "X, Y = X[shuffle], Y[shuffle]\n",
    "\n",
    "print('data shape: ', X.shape)\n",
    "print('label shape:', Y.shape)\n",
    "\n",
    "# Set some variables to hold test, dev, and training data.\n",
    "test_data, test_labels = X[61000:], Y[61000:]\n",
    "dev_data, dev_labels = X[60000:61000], Y[60000:61000]\n",
    "train_data, train_labels = X[:60000], Y[:60000]\n",
    "mini_train_data, mini_train_labels = X[:1000], Y[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "atc2JpWKhWAV"
   },
   "source": [
    "### Part 1:\n",
    "\n",
    "Show a 10x10 grid that visualizes 10 examples of each digit.\n",
    "\n",
    "Notes:\n",
    "* You can use `plt.rc()` for setting the colormap, for example to black and white.\n",
    "* You can use `plt.subplot()` for creating subplots.\n",
    "* You can use `plt.imshow()` for rendering a matrix.\n",
    "* You can use `np.array.reshape()` for reshaping a 1D feature vector into a 2D matrix (for rendering)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "436UeH7JhWAW",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 100 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#def P1(num_examples=10):\n",
    "\n",
    "### STUDENT START ###\n",
    "col = 0\n",
    "row = 0\n",
    "i = 0\n",
    "\n",
    "f,axarr = plt.subplots(10,10)\n",
    "\n",
    "while(col<10):\n",
    "    while(row<10):\n",
    "        if(mini_train_labels[i] == str(col)):\n",
    "            map_num = (np.reshape(mini_train_data[i], (28, 28)) * 255).astype(np.uint8)\n",
    "            axarr[row,col].imshow(map_num)\n",
    "            axarr[row,col].axis('off')\n",
    "            row+=1\n",
    "        i+=1\n",
    "        \n",
    "    row=0\n",
    "    i=0\n",
    "    col+=1\n",
    "\n",
    "plt.style.use('grayscale')\n",
    "plt.show()\n",
    "\n",
    "### STUDENT END ###\n",
    "\n",
    "#P1(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EMQAHr7QhWAX"
   },
   "source": [
    "### Part 2:\n",
    "\n",
    "Produce k-Nearest-Neighbors model with k = [1,3,5,7,9].  Evaluate and show teh performance of each model. For the 1-Nearest Neighbor model, show precision, recall, and F1 for each label. Which is the most difficult digit?\n",
    "\n",
    "Notes:\n",
    "* Train on the mini train set.\n",
    "* Evaluate performance on the dev set.\n",
    "* You can use `KNeighborsClassifier` to produce a k-nearest neighbor model.\n",
    "* You can use `classification_report` to get precision, recall, and F1 results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-it5pn8-hWAY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1 // number of incorrect predictions: 114\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95       116\n",
      "           1       0.82      0.99      0.90        95\n",
      "           2       0.97      0.88      0.92       100\n",
      "           3       0.81      0.88      0.84       104\n",
      "           4       0.87      0.84      0.85        94\n",
      "           5       0.89      0.83      0.86        89\n",
      "           6       0.93      0.96      0.94        98\n",
      "           7       0.91      0.93      0.92       106\n",
      "           8       0.96      0.78      0.86        95\n",
      "           9       0.79      0.80      0.79       103\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      1000\n",
      "   macro avg       0.89      0.88      0.88      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n",
      "k =  3  // number of incorrect predictions: 132\n",
      "k =  5  // number of incorrect predictions: 124\n",
      "k =  7  // number of incorrect predictions: 138\n",
      "k =  9  // number of incorrect predictions: 141\n"
     ]
    }
   ],
   "source": [
    "#def P2(k_values):\n",
    "\n",
    "### STUDENT START ###\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "model.fit(mini_train_data, mini_train_labels)\n",
    "test_predicted_labels = model.predict(dev_data)\n",
    "\n",
    "wrong_prediction = (test_predicted_labels != dev_labels)\n",
    "\n",
    "print('k = 1 // number of incorrect predictions:', np.sum(wrong_prediction))\n",
    "print(classification_report(y_pred=test_predicted_labels,y_true=dev_labels))\n",
    "\n",
    "k = [3,5,7,9]\n",
    "for i in k:\n",
    "    model = KNeighborsClassifier(n_neighbors=i)\n",
    "    model.fit(mini_train_data, mini_train_labels)\n",
    "    test_predicted_labels = model.predict(dev_data)\n",
    "\n",
    "    wrong_prediction = (test_predicted_labels != dev_labels)\n",
    "    print('k = ',i,' // number of incorrect predictions:',np.sum(wrong_prediction))\n",
    "\n",
    "### STUDENT END ###\n",
    "\n",
    "#k_values = [1, 3, 5, 7, 9]\n",
    "#P2(k_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tZc9gzn5hWAZ"
   },
   "source": [
    "ANSWER: The '9' label was the most difficult label to predict for the 1-Nearest Neighbor model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7b6YEAzzhWAa"
   },
   "source": [
    "### Part 3:\n",
    "\n",
    "Produce 1-Nearest Neighbor models using training data of various sizes.  Evaluate and show the performance of each model.  Additionally, show the time needed to measure the performance of each model.\n",
    "\n",
    "Notes:\n",
    "* Train on the train set.\n",
    "* Evaluate on the dev set.\n",
    "* You can use `KNeighborsClassifier` to produce a k-nearest neighbor model.\n",
    "* You can use `time.time()` to measure elapsed time of operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gEpNzDEjhWAa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size = 5,000 // number of incorrect predictions: 55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       116\n",
      "           1       0.94      0.99      0.96        95\n",
      "           2       0.99      1.00      1.00       100\n",
      "           3       0.93      0.93      0.93       104\n",
      "           4       0.94      0.89      0.92        94\n",
      "           5       0.88      0.91      0.90        89\n",
      "           6       0.95      0.99      0.97        98\n",
      "           7       0.94      0.98      0.96       106\n",
      "           8       0.98      0.85      0.91        95\n",
      "           9       0.91      0.90      0.91       103\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      1000\n",
      "   macro avg       0.94      0.94      0.94      1000\n",
      "weighted avg       0.95      0.94      0.94      1000\n",
      "\n",
      "Prediction took:  6.5602641105651855 \n",
      "Evaluation operation took:  0.02190685272216797  seconds.\n",
      "\n",
      "\n",
      "train_size = 10,000 // number of incorrect predictions: 37\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       116\n",
      "           1       0.97      1.00      0.98        95\n",
      "           2       0.97      0.99      0.98       100\n",
      "           3       0.97      0.92      0.95       104\n",
      "           4       0.95      0.98      0.96        94\n",
      "           5       0.92      0.94      0.93        89\n",
      "           6       0.96      0.99      0.97        98\n",
      "           7       0.96      0.97      0.97       106\n",
      "           8       0.98      0.91      0.94        95\n",
      "           9       0.95      0.93      0.94       103\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      1000\n",
      "   macro avg       0.96      0.96      0.96      1000\n",
      "weighted avg       0.96      0.96      0.96      1000\n",
      "\n",
      "Prediction took:  11.618316650390625 \n",
      "Evaluation operation took:  0.015586137771606445  seconds.\n",
      "\n",
      "\n",
      "train_size = 25,000 // number of incorrect predictions: 25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       116\n",
      "           1       0.99      1.00      0.99        95\n",
      "           2       0.98      1.00      0.99       100\n",
      "           3       0.98      0.93      0.96       104\n",
      "           4       0.98      1.00      0.99        94\n",
      "           5       0.93      0.96      0.94        89\n",
      "           6       0.96      0.99      0.97        98\n",
      "           7       0.98      0.99      0.99       106\n",
      "           8       0.98      0.93      0.95        95\n",
      "           9       0.97      0.95      0.96       103\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      1000\n",
      "   macro avg       0.97      0.97      0.97      1000\n",
      "weighted avg       0.98      0.97      0.97      1000\n",
      "\n",
      "Prediction took:  30.087136030197144 \n",
      "Evaluation operation took:  0.01767706871032715  seconds.\n",
      "\n",
      "\n",
      "train_size = 60,000 // number of incorrect predictions: 20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       116\n",
      "           1       1.00      0.99      0.99        95\n",
      "           2       0.99      1.00      1.00       100\n",
      "           3       0.98      0.93      0.96       104\n",
      "           4       0.96      1.00      0.98        94\n",
      "           5       0.96      0.98      0.97        89\n",
      "           6       0.98      1.00      0.99        98\n",
      "           7       0.99      0.98      0.99       106\n",
      "           8       0.99      0.96      0.97        95\n",
      "           9       0.96      0.96      0.96       103\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1000\n",
      "   macro avg       0.98      0.98      0.98      1000\n",
      "weighted avg       0.98      0.98      0.98      1000\n",
      "\n",
      "Prediction took:  68.6303699016571 \n",
      "Evaluation operation took:  0.015002250671386719  seconds.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#def P3(train_sizes, accuracies):\n",
    "\n",
    "### STUDENT START ###\n",
    "\n",
    "#############################\n",
    "# Test on 5000 data points #\n",
    "#############################\n",
    "temp_train_data = train_data[:5000]\n",
    "temp_train_labels = train_labels[:5000]\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "model.fit(temp_train_data, temp_train_labels)\n",
    "\n",
    "temp_start = time.time()\n",
    "test_predicted_labels = model.predict(dev_data)\n",
    "temp_mid = time.time()\n",
    "wrong_prediction = (test_predicted_labels != dev_labels)\n",
    "\n",
    "print('train_size = 5,000 // number of incorrect predictions:', np.sum(wrong_prediction))\n",
    "print(classification_report(y_pred=test_predicted_labels,y_true=dev_labels))\n",
    "temp_end = time.time()\n",
    "print(\"Prediction took: \",temp_mid-temp_start,\"\\nEvaluation operation took: \",temp_end-temp_mid,\" seconds.\\n\\n\")\n",
    "\n",
    "#############################\n",
    "# Test on 10000 data points #\n",
    "#############################\n",
    "temp_train_data = train_data[:10000]\n",
    "temp_train_labels = train_labels[:10000]\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "model.fit(temp_train_data, temp_train_labels)\n",
    "\n",
    "temp_start = time.time()\n",
    "test_predicted_labels = model.predict(dev_data)\n",
    "temp_mid = time.time()\n",
    "wrong_prediction = (test_predicted_labels != dev_labels)\n",
    "\n",
    "print('train_size = 10,000 // number of incorrect predictions:', np.sum(wrong_prediction))\n",
    "print(classification_report(y_pred=test_predicted_labels,y_true=dev_labels))\n",
    "temp_end = time.time()\n",
    "print(\"Prediction took: \",temp_mid-temp_start,\"\\nEvaluation operation took: \",temp_end-temp_mid,\" seconds.\\n\\n\")\n",
    "\n",
    "#############################\n",
    "# Test on 25000 data points #\n",
    "#############################\n",
    "temp_train_data = train_data[:25000]\n",
    "temp_train_labels = train_labels[:25000]\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "model.fit(temp_train_data, temp_train_labels)\n",
    "\n",
    "temp_start = time.time()\n",
    "test_predicted_labels = model.predict(dev_data)\n",
    "temp_mid = time.time()\n",
    "wrong_prediction = (test_predicted_labels != dev_labels)\n",
    "\n",
    "\n",
    "print('train_size = 25,000 // number of incorrect predictions:', np.sum(wrong_prediction))\n",
    "print(classification_report(y_pred=test_predicted_labels,y_true=dev_labels))\n",
    "temp_end = time.time()\n",
    "print(\"Prediction took: \",temp_mid-temp_start,\"\\nEvaluation operation took: \",temp_end-temp_mid,\" seconds.\\n\\n\")\n",
    "\n",
    "#############################\n",
    "# Test on 60000 data points #\n",
    "#############################\n",
    "temp_train_data = train_data\n",
    "temp_train_labels = train_labels\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "model.fit(temp_train_data, temp_train_labels)\n",
    "\n",
    "temp_start = time.time()\n",
    "test_predicted_labels = model.predict(dev_data)\n",
    "temp_mid = time.time()\n",
    "wrong_prediction = (test_predicted_labels != dev_labels)\n",
    "\n",
    "print('train_size = 60,000 // number of incorrect predictions:', np.sum(wrong_prediction))\n",
    "print(classification_report(y_pred=test_predicted_labels,y_true=dev_labels))\n",
    "temp_end = time.time()\n",
    "print(\"Prediction took: \",temp_mid-temp_start,\"\\nEvaluation operation took: \",temp_end-temp_mid,\" seconds.\\n\\n\")\n",
    "\n",
    "### STUDENT END ###\n",
    "\n",
    "#train_sizes = [100, 200, 400, 800, 1600, 3200, 6400, 12800, 25600]\n",
    "#accuracies = []\n",
    "#P3(train_sizes, accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B56lVsKNhWAc"
   },
   "source": [
    "### Part 4:\n",
    "\n",
    "Produce a regression model that predicts accuracy of a 1-Nearest Neighbor model given training set size. Show $R^2$ of the regression model and the accuracies it predicts for training set sizes 60000, 120000, and 1000000.  Show a lineplot of the actual accuracies and predicted accuracies vs. training set size.  What's wrong with using regression here?\n",
    "\n",
    "Apply some transformation that makes the predictions more reasonable.  Show $R^2$ of the improved regression model and the accuracies it predicts for training set sizes 60000, 120000, and 1000000.  Show a lineplot of the actual accuracies and predicted accuracies vs. training set size.\n",
    "\n",
    "Notes:\n",
    "* Train the regression models on all of the (transformed) accuracies estimated in Problem 3.\n",
    "* Evaluate the regression models on all of the (transformed) accuracies estimated in Problem 3.\n",
    "* You can use `LinearRegression` to produce a linear regression model.\n",
    "* Remember that the sklearn `fit()` functions take an input matrix X and output vector Y. So, each input example in X is a vector, even if it contains only a single value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4xE_qIJghWAc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Model #1:\n",
      "\n",
      "Predictions for 60,000; 120,000; and 1,000,000:  [    7.37900294   -57.17526398 -1003.97117881]\n",
      "R2 score:  0.460018167486024\n",
      "\n",
      "\n",
      "Model #2:\n",
      "\n",
      "Predictions for 60,000; 120,000; and 1,000,000:  [1.61802953e+01 3.98189535e+00 4.67311391e-09]\n",
      "R2 score:  0.6631734558871405\n"
     ]
    }
   ],
   "source": [
    "#def P4():\n",
    "\n",
    "### STUDENT START ###\n",
    "\n",
    "train_sizes = [[1000],[5000],[10000],[25000],[60000]]\n",
    "train_accuracy = [114,55,37,25,20]\n",
    "test_sizes = [[60000],[120000],[1000000]]\n",
    "\n",
    "print(\"\\n\\nModel #1:\\n\")\n",
    "model = LinearRegression()\n",
    "model.fit(train_sizes, train_accuracy)\n",
    "print(\"Predictions for 60,000; 120,000; and 1,000,000: \",model.predict(test_sizes))\n",
    "print(\"R2 score: \",model.score(train_sizes, train_accuracy))\n",
    "\n",
    "train_accuracy2 = [np.log(114),np.log(55),np.log(37),np.log(25),np.log(20)]\n",
    "print(\"\\n\\nModel #2:\\n\")\n",
    "model2 = LinearRegression()\n",
    "model2.fit(train_sizes, train_accuracy2)\n",
    "\n",
    "model2_pred = model2.predict(test_sizes)\n",
    "model2_pred_exp = np.zeros(len(model2_pred))\n",
    "for i in range(len(model2_pred)):\n",
    "    model2_pred_exp[i] = np.exp(model2_pred[i])\n",
    "    \n",
    "print(\"Predictions for 60,000; 120,000; and 1,000,000: \",model2_pred_exp)\n",
    "print(\"R2 score: \",model2.score(train_sizes, train_accuracy2))\n",
    "\n",
    "### STUDENT END ###\n",
    "\n",
    "#P4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HYYYL9cGhWAe"
   },
   "source": [
    "ANSWER:  The problem with using regression here is that a straight line regression without a transformation goes negative, which does not make sense in this case.  By applying a log transformation pre-model and then inverting the log post-transformation we keep the model positive and approaching 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "geAQJjGRhWAe"
   },
   "source": [
    "### Part 5:\n",
    "\n",
    "Produce a 1-Nearest Neighbor model and show the confusion matrix. Which pair of digits does the model confuse most often? Show the images of these most often confused digits.\n",
    "\n",
    "Notes:\n",
    "- Train on the mini train set.\n",
    "- Evaluate performance on the dev set.\n",
    "- You can use `confusion_matrix()` to produce a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bq36xaQohWAf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1 // number of incorrect predictions: 114\n",
      "[[111   0   0   0   0   1   3   0   0   1]\n",
      " [  0  94   0   0   0   0   0   0   0   1]\n",
      " [  0   5  88   4   1   0   0   2   0   0]\n",
      " [  0   5   1  91   0   3   0   1   1   2]\n",
      " [  0   3   0   0  79   0   0   2   0  10]\n",
      " [  3   0   0   5   0  74   3   0   1   3]\n",
      " [  1   1   1   0   0   0  94   0   0   1]\n",
      " [  0   4   1   1   0   0   0  99   0   1]\n",
      " [  1   2   0   9   0   5   1   0  74   3]\n",
      " [  1   1   0   2  11   0   0   5   1  82]]\n"
     ]
    }
   ],
   "source": [
    "#def P5():\n",
    "\n",
    "### STUDENT START ###\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "model.fit(mini_train_data, mini_train_labels)\n",
    "test_predicted_labels = model.predict(dev_data)\n",
    "\n",
    "wrong_prediction = (test_predicted_labels != dev_labels)\n",
    "\n",
    "print('k = 1 // number of incorrect predictions:', np.sum(wrong_prediction))\n",
    "print(confusion_matrix(y_pred=test_predicted_labels,y_true=dev_labels))\n",
    "\n",
    "### STUDENT END ###\n",
    "\n",
    "#P5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: 9 and 4 are the most confused numbers with a total of 21 instances of confusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tgqMKb-hhWAh"
   },
   "source": [
    "### Part 6:\n",
    "\n",
    "A common image processing technique is to smooth an image by blurring. The idea is that the value of a particular pixel is estimated as the weighted combination of the original value and the values around it. Typically, the blurring is Gaussian, i.e., the weight of a pixel's influence is determined by a Gaussian function over the distance to the relevant pixel.\n",
    "\n",
    "Implement a simplified Gaussian blur by just using the 8 neighboring pixels like this: the smoothed value of a pixel is a weighted combination of the original value and the 8 neighboring values.\n",
    "\n",
    "Apply your blur filter in 3 ways:\n",
    "- Filter the training data but not the dev data\n",
    "- Filter the dev data but not the training data\n",
    "- Filter both training data and dev data\n",
    "\n",
    "Show the accuracy resulting no filter and from each way you apply the filter.\n",
    "\n",
    "Notes:\n",
    "* Train on the (filtered) mini train set.\n",
    "* Evaluate performance on the (filtered) dev set.\n",
    "* There are Guassian blur filters available, for example in `scipy.ndimage.filters`. You are welcome to experiment with those, but you are likely to get the best results with the simplified version described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lSKHmHGshWAi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No filters // number of incorrect predictions: 114\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95       116\n",
      "           1       0.82      0.99      0.90        95\n",
      "           2       0.97      0.88      0.92       100\n",
      "           3       0.81      0.88      0.84       104\n",
      "           4       0.87      0.84      0.85        94\n",
      "           5       0.89      0.83      0.86        89\n",
      "           6       0.93      0.96      0.94        98\n",
      "           7       0.91      0.93      0.92       106\n",
      "           8       0.96      0.78      0.86        95\n",
      "           9       0.79      0.80      0.79       103\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      1000\n",
      "   macro avg       0.89      0.88      0.88      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      " \n",
      "\n",
      "\n",
      "Mini_train_data filtered // number of incorrect predictions: 88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96       116\n",
      "           1       0.88      0.97      0.92        95\n",
      "           2       0.96      0.93      0.94       100\n",
      "           3       0.86      0.90      0.88       104\n",
      "           4       0.89      0.85      0.87        94\n",
      "           5       0.90      0.89      0.89        89\n",
      "           6       0.93      0.98      0.96        98\n",
      "           7       0.95      0.92      0.94       106\n",
      "           8       0.98      0.86      0.92        95\n",
      "           9       0.81      0.84      0.83       103\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      " \n",
      "\n",
      "\n",
      "Dev_data filtered // number of incorrect predictions: 118\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96       116\n",
      "           1       0.74      0.99      0.85        95\n",
      "           2       0.98      0.83      0.90       100\n",
      "           3       0.84      0.84      0.84       104\n",
      "           4       0.89      0.89      0.89        94\n",
      "           5       0.90      0.82      0.86        89\n",
      "           6       0.91      0.96      0.94        98\n",
      "           7       0.89      0.92      0.90       106\n",
      "           8       0.97      0.78      0.87        95\n",
      "           9       0.80      0.83      0.82       103\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      1000\n",
      "   macro avg       0.89      0.88      0.88      1000\n",
      "weighted avg       0.89      0.88      0.88      1000\n",
      " \n",
      "\n",
      "\n",
      "Both // number of incorrect predictions: 88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95       116\n",
      "           1       0.87      0.97      0.92        95\n",
      "           2       0.96      0.92      0.94       100\n",
      "           3       0.90      0.90      0.90       104\n",
      "           4       0.88      0.87      0.88        94\n",
      "           5       0.92      0.89      0.90        89\n",
      "           6       0.91      0.97      0.94        98\n",
      "           7       0.96      0.90      0.93       106\n",
      "           8       0.98      0.87      0.92        95\n",
      "           9       0.81      0.87      0.84       103\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      " \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#def P6():\n",
    "    \n",
    "### STUDENT START ###\n",
    "f_mini_train_data = np.zeros(mini_train_data.shape)\n",
    "f_dev_data = np.zeros(dev_data.shape)\n",
    "temp_list = np.zeros(mini_train_data[0].shape)\n",
    "sum_n = float()\n",
    "\n",
    "for i in range(len(mini_train_data)):\n",
    "    temp_matrix = np.reshape(mini_train_data[i], (28, 28))\n",
    "    list_n = 0\n",
    "    for j in range(28):\n",
    "        for k in range(28):\n",
    "            n = 1\n",
    "            sum_n = temp_matrix[j][k]\n",
    "            if(j-1>=0):\n",
    "                sum_n += temp_matrix[j-1][k]\n",
    "                n += 1\n",
    "                if(k-1>=0):\n",
    "                    sum_n += temp_matrix[j-1][k-1]\n",
    "                    n += 1\n",
    "                if(k+1<=27):\n",
    "                    sum_n += temp_matrix[j-1][k+1]\n",
    "                    n += 1\n",
    "            if(j+1<=27):\n",
    "                sum_n += temp_matrix[j+1][k]\n",
    "                n += 1\n",
    "                if(k-1>=0):\n",
    "                    sum_n += temp_matrix[j+1][k-1]\n",
    "                    n += 1\n",
    "                if(k+1<=27):\n",
    "                    sum_n += temp_matrix[j+1][k+1]\n",
    "                    n += 1\n",
    "            if(k-1>=0):\n",
    "                sum_n += temp_matrix[j][k-1]\n",
    "                n += 1\n",
    "            if(k+1<=27):\n",
    "                sum_n += temp_matrix[j][k+1]\n",
    "                n += 1\n",
    "            temp_list[list_n] = float(sum_n/n)\n",
    "            list_n+=1\n",
    "    f_mini_train_data[i] = np.array(temp_list,copy=True)\n",
    "\n",
    "\n",
    "temp_list = np.zeros(dev_data[0].shape)\n",
    "\n",
    "for i in range(len(dev_data)):\n",
    "    temp_matrix = np.reshape(dev_data[i], (28, 28))\n",
    "    list_n = 0\n",
    "    for j in range(28):\n",
    "        for k in range(28):\n",
    "            n = 1\n",
    "            sum_n = temp_matrix[j][k]\n",
    "            if(j-1>=0):\n",
    "                sum_n += temp_matrix[j-1][k]\n",
    "                n += 1\n",
    "                if(k-1>=0):\n",
    "                    sum_n += temp_matrix[j-1][k-1]\n",
    "                    n += 1\n",
    "                if(k+1<=27):\n",
    "                    sum_n += temp_matrix[j-1][k+1]\n",
    "                    n += 1\n",
    "            if(j+1<=27):\n",
    "                sum_n += temp_matrix[j+1][k]\n",
    "                n += 1\n",
    "                if(k-1>=0):\n",
    "                    sum_n += temp_matrix[j+1][k-1]\n",
    "                    n += 1\n",
    "                if(k+1<=27):\n",
    "                    sum_n += temp_matrix[j+1][k+1]\n",
    "                    n += 1\n",
    "            if(k-1>=0):\n",
    "                sum_n += temp_matrix[j][k-1]\n",
    "                n += 1\n",
    "            if(k+1<=27):\n",
    "                sum_n += temp_matrix[j][k+1]\n",
    "                n += 1\n",
    "            temp_list[list_n] = float(sum_n/n)\n",
    "            list_n+=1\n",
    "    f_dev_data[i] = np.array(temp_list,copy=True)\n",
    "\n",
    "\n",
    "## No Filters\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "model.fit(mini_train_data, mini_train_labels)\n",
    "test_predicted_labels = model.predict(dev_data)\n",
    "\n",
    "print('No filters // number of incorrect predictions:', np.sum(wrong_prediction))\n",
    "print(classification_report(y_pred=test_predicted_labels,y_true=dev_labels), \"\\n\\n\")\n",
    "\n",
    "\n",
    "## Mini_train_data filtered\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "model.fit(f_mini_train_data, mini_train_labels)\n",
    "test_predicted_labels = model.predict(dev_data)\n",
    "\n",
    "wrong_prediction = (test_predicted_labels != dev_labels)\n",
    "\n",
    "print('Mini_train_data filtered // number of incorrect predictions:', np.sum(wrong_prediction))\n",
    "print(classification_report(y_pred=test_predicted_labels,y_true=dev_labels), \"\\n\\n\")\n",
    "\n",
    "## Dev_data filtered\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "model.fit(mini_train_data, mini_train_labels)\n",
    "test_predicted_labels = model.predict(f_dev_data)\n",
    "\n",
    "wrong_prediction = (test_predicted_labels != dev_labels)\n",
    "\n",
    "print('Dev_data filtered // number of incorrect predictions:', np.sum(wrong_prediction))\n",
    "print(classification_report(y_pred=test_predicted_labels,y_true=dev_labels), \"\\n\\n\")\n",
    "\n",
    "## Both filtered\n",
    "model = KNeighborsClassifier(n_neighbors=1)\n",
    "model.fit(f_mini_train_data, mini_train_labels)\n",
    "test_predicted_labels = model.predict(f_dev_data)\n",
    "\n",
    "wrong_prediction = (test_predicted_labels != dev_labels)\n",
    "\n",
    "print('Both // number of incorrect predictions:', np.sum(wrong_prediction))\n",
    "print(classification_report(y_pred=test_predicted_labels,y_true=dev_labels), \"\\n\\n\")\n",
    "\n",
    "### STUDENT END ###\n",
    "\n",
    "#P6()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LtgepWfAhWAk"
   },
   "source": [
    "### Part 7:\n",
    "\n",
    "Produce two Naive Bayes models and evaluate their performances.  Recall that Naive Bayes estimates P(feature|label), where each label is a categorical, not a real number.\n",
    "\n",
    "For the first model, map pixel values to either 0 or 1, representing white or black - you should pre-process the data or use `BernoulliNB`'s `binarize` parameter.  Use some reasonable threshold to separate white from black.  Use `BernoulliNB` to produce the model.\n",
    "\n",
    "For the second model, map pixel values to either 0, 1, or 2, representing white, gray, or black - you should pre-process the data.  Use some reasonable thresholds to separate white from gray from black.  Use `MultinomialNB` to produce the model. \n",
    "\n",
    "Show the Bernoulli model accuracy and the Multinomial model accuracy.\n",
    "\n",
    "Notes:\n",
    "* Train on the mini train set.\n",
    "* Evaluate performance on the dev set.\n",
    "* `sklearn`'s Naive Bayes methods can handle real numbers, but for this exercise explicitly do the mapping to categoricals. \n",
    "\n",
    "Does the multinomial version improve the results? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eGpH-4IQhWAk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.84\n",
      "\n",
      "Feature probabilities\n",
      " [[1.23453742e-05 7.69218935e-06 1.07524569e-05 ... 9.09074380e-06\n",
      "  1.13633781e-05 9.52362812e-06]\n",
      " [1.23453742e-05 7.69218935e-06 1.07524569e-05 ... 9.09074380e-06\n",
      "  1.13633781e-05 9.52362812e-06]\n",
      " [1.23453742e-05 7.69218935e-06 1.07524569e-05 ... 9.09074380e-06\n",
      "  1.13633781e-05 9.52362812e-06]\n",
      " ...\n",
      " [1.23453742e-05 7.69218935e-06 1.07524569e-05 ... 9.09074380e-06\n",
      "  1.13633781e-05 9.52362812e-06]\n",
      " [1.23453742e-05 7.69218935e-06 1.07524569e-05 ... 9.09074380e-06\n",
      "  1.13633781e-05 9.52362812e-06]\n",
      " [1.23453742e-05 7.69218935e-06 1.07524569e-05 ... 9.09074380e-06\n",
      "  1.13633781e-05 9.52362812e-06]]\n",
      "\n",
      "Prior probabilities\n",
      " [0.081 0.13  0.093 0.107 0.101 0.089 0.096 0.11  0.088 0.105]\n",
      "\n",
      "\n",
      "Accuracy: 0.82\n",
      "\n",
      "Feature probabilities\n",
      " [[4.46791909e-08 6.63403429e-08 4.58173690e-08 ... 5.04648214e-08\n",
      "  4.94932289e-08 5.39147965e-08]\n",
      " [4.46791909e-08 6.63403429e-08 4.58173690e-08 ... 5.04648214e-08\n",
      "  4.94932289e-08 5.39147965e-08]\n",
      " [4.46791909e-08 6.63403429e-08 4.58173690e-08 ... 5.04648214e-08\n",
      "  4.94932289e-08 5.39147965e-08]\n",
      " ...\n",
      " [4.46791909e-08 6.63403429e-08 4.58173690e-08 ... 5.04648214e-08\n",
      "  4.94932289e-08 5.39147965e-08]\n",
      " [4.46791909e-08 6.63403429e-08 4.58173690e-08 ... 5.04648214e-08\n",
      "  4.94932289e-08 5.39147965e-08]\n",
      " [4.46791909e-08 6.63403429e-08 4.58173690e-08 ... 5.04648214e-08\n",
      "  4.94932289e-08 5.39147965e-08]]\n",
      "\n",
      "Prior probabilities\n",
      " [0.081 0.13  0.093 0.107 0.101 0.089 0.096 0.11  0.088 0.105]\n"
     ]
    }
   ],
   "source": [
    "#def P7():\n",
    "\n",
    "### STUDENT START ###\n",
    "\n",
    "alpha = .001\n",
    "clf = BernoulliNB(alpha=alpha, binarize=0.1)\n",
    "clf.fit(mini_train_data, mini_train_labels)\n",
    "print('Accuracy: %3.2f' %clf.score(dev_data, dev_labels))\n",
    "\n",
    "print('\\nFeature probabilities\\n', np.exp(clf.feature_log_prob_).T)\n",
    "print('\\nPrior probabilities\\n', np.exp(clf.class_log_prior_))\n",
    "\n",
    "\n",
    "pp_mini_train_data = np.zeros(mini_train_data.shape)\n",
    "for i in range(len(mini_train_data)):\n",
    "    for j in range(len(mini_train_data[i])):\n",
    "        if mini_train_data[i][j]<0.1:\n",
    "            pp_mini_train_data[i][j] = 0\n",
    "        if mini_train_data[i][j]>=0.1 and mini_train_data[i][j]<=0.95:\n",
    "            pp_mini_train_data[i][j] = 1\n",
    "        if mini_train_data[i][j]>0.95:\n",
    "            pp_mini_train_data[i][j] = 2\n",
    "\n",
    "\n",
    "clf = MultinomialNB(alpha=alpha)\n",
    "clf.fit(pp_mini_train_data, mini_train_labels)\n",
    "print('\\n\\nAccuracy: %3.2f' %clf.score(dev_data, dev_labels))\n",
    "\n",
    "print('\\nFeature probabilities\\n', np.exp(clf.feature_log_prob_).T)\n",
    "print('\\nPrior probabilities\\n', np.exp(clf.class_log_prior_))\n",
    "\n",
    "### STUDENT END ###\n",
    "\n",
    "#P7()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zNLrgggohWAm"
   },
   "source": [
    "ANSWER: In this case the multinomial does not improve the results. Recognizing a number is generally made easier by simplifying the feature set.  For example, trying to see a number in a series of similar dots for an eye exam can be hard, but reading a black number on white paper is easier.  Higher contrast is useful in this instance.  However, there may be other types of images that suffer from such techniques.  For instance, a black and white image of a face would be less distinctive than an image with gray included.  Additional shades of gray or even colors may also help, depending on the available data.\n",
    "\n",
    "As a result, simplifying to binary data in this instance is likely the best way to go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PqjbRLg7hWAm"
   },
   "source": [
    "### Part 8:\n",
    "\n",
    "Search across several values for the LaPlace smoothing parameter (alpha) to find its effect on a Bernoulli Naive Bayes model's performance.  Show the accuracy at each alpha value.\n",
    "\n",
    "Notes:\n",
    "* Train on the mini train set.\n",
    "* Vary alpha and evaulate performance using `GridSearchCV` to cross-validate.\n",
    "* Cross-validation is based on partitions of the training data, so results will be a bit different than if you used the dev set to evaluate performance.\n",
    "\n",
    "What is the best value for alpha? What is the accuracy when alpha is near 0? Is this what you'd expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0AvZ-Wp3hWAn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on training set:  {'alpha': 0.0001} \n",
      "\n",
      "\n",
      "Grid scores on training set:\n",
      "0.824 (+/-0.064) for {'alpha': 1e-10}\n",
      "0.838 (+/-0.059) for {'alpha': 0.0001}\n",
      "0.838 (+/-0.063) for {'alpha': 0.001}\n",
      "0.835 (+/-0.067) for {'alpha': 0.01}\n",
      "0.831 (+/-0.068) for {'alpha': 0.1}\n",
      "0.822 (+/-0.069) for {'alpha': 0.5}\n",
      "0.821 (+/-0.067) for {'alpha': 1.0}\n",
      "0.811 (+/-0.067) for {'alpha': 2.0}\n",
      "0.761 (+/-0.066) for {'alpha': 10.0}\n",
      "\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.86      0.90       116\n",
      "           1       0.90      0.94      0.92        95\n",
      "           2       0.87      0.92      0.89       100\n",
      "           3       0.75      0.77      0.76       104\n",
      "           4       0.75      0.89      0.82        94\n",
      "           5       0.73      0.76      0.75        89\n",
      "           6       0.89      0.88      0.88        98\n",
      "           7       0.99      0.84      0.91       106\n",
      "           8       0.72      0.74      0.73        95\n",
      "           9       0.78      0.72      0.75       103\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      1000\n",
      "   macro avg       0.83      0.83      0.83      1000\n",
      "weighted avg       0.84      0.83      0.83      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#def P8(alphas):\n",
    "\n",
    "### STUDENT START ###\n",
    "params = {'alpha': [1.0e-10, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]}\n",
    "\n",
    "nbb=BernoulliNB()\n",
    "clf = GridSearchCV(nbb,param_grid=params,scoring='accuracy',cv=5,iid=False)\n",
    "clf.fit(mini_train_data, mini_train_labels)\n",
    "\n",
    "\n",
    "print(\"Best parameters set found on training set: \",clf.best_params_,\"\\n\\n\")\n",
    "print(\"Grid scores on training set:\")\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "        \n",
    "print(\"\\n\\nClassification report:\")\n",
    "dev_pred = clf.predict(dev_data)\n",
    "print(classification_report(dev_labels, dev_pred))\n",
    "\n",
    "### STUDENT END ###\n",
    "\n",
    "# alphas = {'alpha': [1.0e-10, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]}\n",
    "# nb = P8(alphas)\n",
    "# print()\n",
    "# print(\"Best alpha = \", nb.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1yEg9keThWAp"
   },
   "source": [
    "ANSWER:  The best value for alpha is 0.0001 based on GridSearchCV cross-validation.  This makes sense because all of the factors occur with reasonable probabilities in the test set, so low smoothing is needed to coalesce the modelaround a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B07GDiDdhWAq"
   },
   "source": [
    "### Part 9:\n",
    "\n",
    "Produce a model using Gaussian Naive Bayes, which is intended for real-valued features, and evaluate performance. You will notice that it does not work so well. Diagnose the problem and apply a simple fix so that the model accuracy is around the same as for a Bernoulli Naive Bayes model. Show the model accuracy before your fix and the model accuracy after your fix.  Explain your solution.\n",
    "\n",
    "Notes:\n",
    "* Train on the mini train set.\n",
    "* Evaluate performance on the dev set.\n",
    "* Consider the effects of theta and sigma.  These are stored in the model's `theta_` and `sigma_` attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gBLbTMWChWAq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.58\n",
      "Accuracy: 0.80\n"
     ]
    }
   ],
   "source": [
    "#def P9():\n",
    "\n",
    "### STUDENT END ###\n",
    "clf = GaussianNB()\n",
    "clf.fit(mini_train_data, mini_train_labels)\n",
    "print('Accuracy: %3.2f' %clf.score(dev_data, dev_labels))\n",
    "\n",
    "\n",
    "clf2 = GaussianNB(var_smoothing=0.1)\n",
    "clf2.fit(mini_train_data, mini_train_labels)\n",
    "print('Accuracy: %3.2f' %clf2.score(dev_data, dev_labels))\n",
    "\n",
    "\n",
    "### STUDENT END ###\n",
    "\n",
    "#P9()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1SyHTEJohWAt"
   },
   "source": [
    "ANSWER: When looking at theta and sigma, we see that small differences in variance are much larger relative to the measured variances than differences in means. By adding a portion of the largest variance to all variances we smooth the covariance, avoiding overfitting and improving the model to something closer to Bernoulli naive bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dgZMuc1VhWAt"
   },
   "source": [
    "### Part 10:\n",
    "\n",
    "Because Naive Bayes produces a generative model, you can use it to generate digit images.\n",
    "\n",
    "Produce a Bernoulli Naive Bayes model and then use it to generate a 10x20 grid with 20 example images of each digit. Each pixel output should be either 0 or 1, based on comparing some randomly generated number to the estimated probability of the pixel being either 0 or 1.  Show the grid.\n",
    "\n",
    "Notes:\n",
    "* You can use np.random.rand() to generate random numbers from a uniform distribution.\n",
    "* The estimated probability of each pixel being 0 or 1 is stored in the model's `feature_log_prob_` attribute. You can use `np.exp()` to convert a log probability back to a probability.\n",
    "\n",
    "How do the generated digit images compare to the training digit images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ktii-Mp-hWAu"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 200 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#def P10(num_examples):\n",
    "\n",
    "### STUDENT START ###\n",
    "alpha = .0001\n",
    "clf = BernoulliNB(alpha=alpha)\n",
    "clf.fit(mini_train_data, mini_train_labels)\n",
    "\n",
    "new_image = np.zeros(784)\n",
    "\n",
    "f,axarr = plt.subplots(10,20)\n",
    "\n",
    "for i in range(len(clf.feature_log_prob_)):\n",
    "    prob_pixel = np.exp(clf.feature_log_prob_[i])\n",
    "    for j in range(20):\n",
    "        rand_pixels = np.random.rand(784)\n",
    "        for k in range(len(prob_pixel)):\n",
    "            if rand_pixels[k] >= prob_pixel[k]:\n",
    "                new_image[k] = 1\n",
    "            else:\n",
    "                new_image[k] = 0\n",
    "        axarr[i,j].imshow((np.reshape(new_image, (28, 28)) * 255).astype(np.uint8))\n",
    "        axarr[i,j].axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "### STUDENT END ###\n",
    "\n",
    "\n",
    "#P10(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SuQd1fTGhWAw"
   },
   "source": [
    "ANSWER: The generated images are vaguely recognizable.  They're not as crisp, but knowing what they are you can recognize the number generated in most cases.  It looks like a pre-weighted Monte Carlo simulation used to create approximations of each number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ksHMg73uhWAx"
   },
   "source": [
    "### Part 11:\n",
    "\n",
    "Recall that a strongly calibrated classifier is rougly 90% accurate when the posterior probability of the predicted class is 0.9. A weakly calibrated classifier is more accurate when the posterior probability of the predicted class is 90% than when it is 80%. A poorly calibrated classifier has no positive correlation between posterior probability and accuracy.  \n",
    "\n",
    "Produce a Bernoulli Naive Bayes model.  Evaluate performance: partition the dev set into several buckets based on the posterior probabilities of the predicted classes - think of a bin in a histogram- and then estimate the accuracy for each bucket. So, for each prediction, find the bucket to which the maximum posterior probability belongs, and update \"correct\" and \"total\" counters accordingly.  Show the accuracy for each bucket.\n",
    "\n",
    "Notes:\n",
    "* Train on the mini train set.\n",
    "* Evaluate perfromance on the dev set.\n",
    "* Apply a reasonable Laplace smoothing (alpha) value.\n",
    "\n",
    "How would you characterize the calibration for this Bernoulli Naive Bayes model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a1N-St12hWAy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of  0.9  : 0.44\n",
      "Accuracy of  0.999  : 0.55\n",
      "Accuracy of  0.99999  : 0.51\n",
      "Accuracy of  0.9999999  : 0.57\n",
      "Accuracy of  0.999999999  : 0.70\n",
      "Accuracy of  0.99999999999  : 0.72\n",
      "Accuracy of  0.9999999999999  : 0.80\n",
      "Accuracy of  1.0  : 0.95\n"
     ]
    }
   ],
   "source": [
    "#def P11(buckets, correct, total):\n",
    "    \n",
    "### STUDENT START ###\n",
    "alpha = .0001\n",
    "clf = BernoulliNB(alpha=alpha)\n",
    "clf.fit(mini_train_data, mini_train_labels)\n",
    "\n",
    "buckets = {\"0.5\": [], \"0.9\": [], \"0.999\": [], \"0.99999\": [], \"0.9999999\": [], \n",
    "           \"0.999999999\": [], \"0.99999999999\": [], \"0.9999999999999\": [], \"1.0\": []}\n",
    "\n",
    "prob_dist = clf.predict_proba(dev_data)\n",
    "\n",
    "for i in range(len(prob_dist)):\n",
    "    if max(prob_dist[i]) <= 0.5:\n",
    "        buckets[\"0.5\"].append(i)\n",
    "    elif max(prob_dist[i]) <= 0.9:\n",
    "        buckets[\"0.9\"].append(i)\n",
    "    elif max(prob_dist[i]) <= 0.999:\n",
    "        buckets[\"0.999\"].append(i)\n",
    "    elif max(prob_dist[i]) <= 0.99999:\n",
    "        buckets[\"0.99999\"].append(i)\n",
    "    elif max(prob_dist[i]) <= 0.9999999:\n",
    "        buckets[\"0.9999999\"].append(i)\n",
    "    elif max(prob_dist[i]) <= 0.999999999:\n",
    "        buckets[\"0.999999999\"].append(i)\n",
    "    elif max(prob_dist[i]) <= 0.99999999999:\n",
    "        buckets[\"0.99999999999\"].append(i)\n",
    "    elif max(prob_dist[i]) <= 0.9999999999999:\n",
    "        buckets[\"0.9999999999999\"].append(i)\n",
    "    else:\n",
    "        buckets[\"1.0\"].append(i)\n",
    "\n",
    "\n",
    "for i in list(buckets.keys()):\n",
    "    if len(buckets[i]) > 0:\n",
    "        print('Accuracy of ',i,' : %3.2f' %clf.score(dev_data[buckets[i]], dev_labels[buckets[i]]))\n",
    "    \n",
    "\n",
    "                \n",
    "### STUDENT END ###\n",
    "\n",
    "# buckets = [0.5, 0.9, 0.999, 0.99999, 0.9999999, 0.999999999, 0.99999999999, 0.9999999999999, 1.0]\n",
    "# correct = [0 for i in buckets]\n",
    "# total = [0 for i in buckets]\n",
    "\n",
    "# P11(buckets, correct, total)\n",
    "\n",
    "# for i in range(len(buckets)):\n",
    "#     accuracy = 0.0\n",
    "#     if (total[i] > 0): accuracy = correct[i] / total[i]\n",
    "#     print('p(pred) is %.13f to %.13f    total = %3d    accuracy = %.3f' % (0 if i==0 else buckets[i-1], buckets[i], total[i], accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h-4qQsrrhWA1"
   },
   "source": [
    "ANSWER: This is a weakly calibrated classifer.  There is a directional relationship between predicted accuracy and test accuracy, but the actual accuracy decreases much faster than predicted accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jLDISyh4hWA1"
   },
   "source": [
    "### Part 12 EXTRA CREDIT:\n",
    "\n",
    "Design new features to see if you can produce a Bernoulli Naive Bayes model with better performance.  Show the accuracy of a model based on the original features and the accuracy of the model based on the new features.\n",
    "\n",
    "Here are a few ideas to get you started:\n",
    "- Try summing or averaging the pixel values in each row.\n",
    "- Try summing or averaging the pixel values in each column.\n",
    "- Try summing or averaging the pixel values in each square block. (pick various block sizes)\n",
    "- Try counting the number of enclosed regions. (8 usually has 2 enclosed regions, 9 usually has 1, and 7 usually has 0)\n",
    "\n",
    "Notes:\n",
    "* Train on the mini train set (enhanced to comprise the new features).\n",
    "* Evaulate performance on the dev set.\n",
    "* Ensure that your code is well commented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-P7h-t2ThWA2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vnicholascirella/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py:480: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    }
   ],
   "source": [
    "#def P12():\n",
    "\n",
    "### STUDENT START ###\n",
    "\n",
    "def trans_in(data_in):\n",
    "    temp_data = np.zeros(6*28)\n",
    "    i = 0\n",
    "    n = 0\n",
    "    while i<784:\n",
    "        temp_data[n] = sum(data_in[i+1:i+5])/4\n",
    "        n += 1\n",
    "        temp_data[n] = sum(data_in[i+5:i+9])/4\n",
    "        n += 1\n",
    "        temp_data[n] = sum(data_in[i+9:i+13])/4\n",
    "        n += 1\n",
    "        temp_data[n] = sum(data_in[i+13:i+17])/4\n",
    "        n += 1\n",
    "        temp_data[n] = sum(data_in[i+17:i+21])/4\n",
    "        n += 1\n",
    "        temp_data[n] = sum(data_in[i+21:i+25])/4\n",
    "        n += 1\n",
    "        i += 28\n",
    "    return temp_data\n",
    "\n",
    "fil_mini_train_data = np.zeros([1000,(28*6)])\n",
    "fil_dev_data = np.zeros([1000,(28*6)])\n",
    "\n",
    "for i in range(len(mini_train_data)):\n",
    "    temp = trans_in(mini_train_data[i])\n",
    "    fil_mini_train_data[i] = np.array(temp,copy=True)\n",
    "        \n",
    "for i in range(len(dev_data)):\n",
    "    temp = trans_in(dev_data[i])\n",
    "    fil_mini_train_data[i] = np.array(temp,copy=True)\n",
    "    \n",
    "\n",
    "alpha = 0.001\n",
    "clf = BernoulliNB(alpha=alpha)\n",
    "clf.fit(fil_mini_train_data, mini_train_labels)\n",
    "print('Accuracy: %3.2f' %clf.score(fil_dev_data, dev_labels))\n",
    "    \n",
    "### STUDENT END ###\n",
    "\n",
    "#P12()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "firstname_lastname_p1.ipynb",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "https://github.com/MIDS-W207/Master/blob/master/Projects/firstname_lastname_p1.ipynb",
     "timestamp": 1557957807607
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
